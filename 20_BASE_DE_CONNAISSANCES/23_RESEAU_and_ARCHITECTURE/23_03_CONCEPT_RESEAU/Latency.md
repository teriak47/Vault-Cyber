---
aliases:
  - Latence
  - Lag
  - Network Latency
  - D√©lai de transmission
  - Transmission Delay
  - Round Trip Time
  - RTT
archetype: concept-reseau
couche_osi:
  - "Couche 1 - Physique"
  - "Couche 2 - Liaison"
  - "Couche 3 - R√©seau"
  - "Couche 4 - Transport"
technologie:
  - R√©seaux IP
  - TCP/IP
cssclasses:
  - max
tags:
  - latence
  - reseau
  - reseau/performance
  - concept/definition
  - modele-osi
  - modele/tcp-ip
  - protocole/tcp
  - protocole/udp
  - mecanisme/encapsulation
  - communication/reseau
  - reseau/congestion
  - materiel/routeur
  - materiel/switch
  - internet
  - latence/propagation
  - latence/traitement
  - latence/file-attente
  - latence/serialisation
  - reseau/rtt
  - reseau/temps-de-reponse
  - application/voip
  - application/jeux-en-ligne
---

# Latency

> [!abstract] D√©finition
> La **latence r√©seau** (ou simplement *latence*) repr√©sente le d√©lai de temps pendant la transmission de donn√©es sur un r√©seau. Elle est le temps n√©cessaire √† un paquet de donn√©es pour voyager de la source √† la destination, mesur√© g√©n√©ralement en millisecondes (ms). Une latence √©lev√©e signifie un temps de r√©ponse lent, tandis qu'une faible latence indique des temps de r√©ponse rapides.

## ‚öôÔ∏è M√©canisme & Fonctionnement
La latence est la somme des retards cumul√©s √† diff√©rentes √©tapes du parcours d'un paquet de donn√©es √† travers le r√©seau. Plusieurs facteurs contribuent √† cette somme :

*   **Latence de Propagation** : C'est le temps n√©cessaire au signal pour traverser physiquement le support de transmission (c√¢ble √† fibres optiques, cuivre, ondes radio). Elle est directement influenc√©e par la distance g√©ographique entre la source et la destination et la vitesse de la lumi√®re dans le m√©dium. Par exemple, la lumi√®re voyage √† environ 4,9 microsecondes par kilom√®tre dans un c√¢ble √† fibre optique.
*   **Latence de Traitement (Processing Latency)** : Le temps que les √©quipements r√©seau (routeurs, commutateurs, pare-feu, serveurs) mettent √† traiter, inspecter et acheminer les paquets de donn√©es. Chaque "saut" (hop) via un p√©riph√©rique r√©seau ajoute un l√©ger d√©lai de traitement.
*   **Latence de File d'attente (Queuing Latency)** : Le temps que les paquets de donn√©es passent √† attendre dans les tampons (buffers) ou les files d'attente des p√©riph√©riques r√©seau en raison de la congestion du r√©seau ou de la surcharge des √©quipements.
*   **Latence de S√©rialisation (Serialization Latency)** : Le temps n√©cessaire pour convertir les donn√©es en un format binaire (bits) et les placer sur le support de transmission ("on the wire"). Ce d√©lai d√©pend de la vitesse de la liaison et de la taille du paquet.

D'autres facteurs incluent la congestion du r√©seau, les limitations mat√©rielles (√©quipements obsol√®tes ou surcharg√©s), la surcharge des protocoles (le protocole TCP, par exemple, introduit plus de surcharge pour la correction d'erreurs et les retransmissions que l'UDP), et la performance des serveurs.

### Encapsulation / Traitement
L'**encapsulation** et la **d√©capsulation** sont des processus fondamentaux dans le mod√®le OSI et TCP/IP, et chacun d'eux contribue √† la latence de traitement :

*   **Entr√©e** : Un bloc de donn√©es (Service Data Unit - SDU) arrive d'une couche sup√©rieure. Par exemple, au niveau de la couche transport, des segments TCP ou des datagrammes UDP arrivent de la couche session.
*   **Action** :
    1.  **Encapsulation** (Sens descendant) : Chaque couche ajoute ses propres informations de contr√¥le (en-t√™tes et parfois pieds de page) au SDU pour cr√©er une Unit√© de Donn√©es de Protocole (PDU). Par exemple, la couche R√©seau ajoute l'en-t√™te IP (adresses IP source/destination, TTL) √† un segment TCP pour former un paquet IP. Ce processus de "conditionnement" prend du temps.
    2.  **D√©capsulation** (Sens ascendant) : √Ä la r√©ception, chaque couche supprime l'en-t√™te et le pied de page correspondant, puis transmet les donn√©es restantes √† la couche sup√©rieure. Ce retrait et l'inspection des informations de contr√¥le introduisent √©galement un d√©lai.
*   **Sortie** : Le PDU est transmis √† la couche inf√©rieure pour un traitement suppl√©mentaire (encapsulation) ou le SDU est transmis √† la couche sup√©rieure (d√©capsulation).

Ces ajouts et retraits d'en-t√™tes, ainsi que les d√©cisions de routage et de commutation bas√©es sur ces informations, contribuent √† la latence de traitement √† chaque niveau du r√©seau. Des √©quipements optimis√©s sont n√©cessaires pour minimiser ces retards.

```mermaid
sequenceDiagram
    participant C as Client (Source)
    participant R1 as Routeur 1
    participant R2 as Routeur 2
    participant S as Serveur (Destination)

    C->>R1: Paquet de donn√©es
    R1-->>R1: Traitement (D√©lai de Traitement, File d'attente)
    R1->>R2: Paquet de donn√©es (D√©lai de Propagation, S√©rialisation)
    R2-->>R2: Traitement (D√©lai de Traitement, File d'attente)
    R2->>S: Paquet de donn√©es (D√©lai de Propagation, S√©rialisation)
    S-->>S: Traitement (R√©ception)
    S->>R2: R√©ponse (ACK)
    R2-->>R2: Traitement
    R2->>R1: R√©ponse (ACK)
    R1-->>R1: Traitement
    R1->>C: R√©ponse (ACK)
```
Le temps total de cet √©change aller-retour est appel√© **Round Trip Time (RTT)**, qui est une mesure courante de la latence.

## üí° Cas d'Usage Typique
Une faible latence est cruciale pour garantir la performance et la r√©activit√© de nombreuses applications et services :
1.  **Communication en temps r√©el** : Les applications de voix sur IP (VoIP), de visioconf√©rence et de collaboration d√©pendent d'une faible latence pour des conversations fluides et sans d√©calage.
2.  **Jeux en ligne** : La latence (souvent appel√©e "lag" par les joueurs) impacte directement l'exp√©rience utilisateur. Une latence √©lev√©e peut rendre un jeu injouable en raison de retards entre les actions du joueur et les r√©ponses du serveur.
3.  **Transactions financi√®res √† haute fr√©quence** : Dans le trading algorithmique, chaque milliseconde compte. Une latence minimale est essentielle pour l'ex√©cution rapide des ordres et l'avantage concurrentiel.
4.  **Services Cloud et Applications Distribu√©es** : Pour les applications bas√©es sur le cloud et les environnements de travail √† distance, une faible latence garantit un acc√®s rapide aux donn√©es et aux applications, am√©liorant la productivit√©.
5.  **Analyse en temps r√©el et IoT** : Les syst√®mes collectant et traitant des donn√©es de capteurs en temps r√©el n√©cessitent une latence minimale pour une prise de d√©cision rapide et efficace.

## ‚ö†Ô∏è Limitations & Probl√®mes
> [!warning] Points d'attention
> *   **Performance des applications** : Une latence √©lev√©e ralentit consid√©rablement les temps de r√©ponse des applications, entra√Ænant une exp√©rience utilisateur frustrante et une baisse de la productivit√©.
> *   **D√©bit r√©duit** : Bien que distincte de la bande passante, une latence √©lev√©e peut r√©duire le d√©bit effectif des donn√©es transf√©r√©es, car le temps d'attente entre les envois et les accus√©s de r√©ception augmente.
> *   **Gigue (Jitter)** : La variation de la latence entre les paquets (gigue) est particuli√®rement probl√©matique pour les applications en temps r√©el, entra√Ænant des coupures audio ou vid√©o et des performances incoh√©rentes.
> *   **Fiabilit√©** : Des niveaux de latence tr√®s √©lev√©s peuvent entra√Æner des abandons de connexion et des √©checs de syst√®me, en particulier pour les protocoles sensibles au temps.

## üîó Notes Connexes
*   **Protocole li√©** : TCP (Transmission Control Protocol), UDP (User Datagram Protocol)
*   **Mat√©riel** : Router, Switch, Firewall
*   **Concept Connexe** : Bandwidth, Throughput, Jitter